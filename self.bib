@inproceedings{Louthan2009,
  author    = {George Louthan and
               Collin McMillan and
               Christopher Johnson and
               John Hale},
  title     = {Toward Robust and Extensible Automatic Protocol Identification},
  booktitle = {International Conference on Internet Computing},
  year      = {2009},
  pages     = {104-108},
}

@inproceedings{Roberts2010,
  author    = {Warren Roberts and
               Christopher Johnson and
               John Hale},
  title     = {Transparent Emergency Data Destruction},
  booktitle = {The 5th International Conference on Information-Warfare \& Security},
  year      = {2010},
  pages     = {271-278},

}

@presentation{JohnsonYazdanbakhsh2012,
    author = {Christopher J. Johnson and
              Arash Yazdanbakhsh},
    title = {A minimal model of motion tuning in middle temporal visual cortex},
    type = {poster},
    organization = {16th International Conference on Cognitive and Neural Systems},
    address = {Boston, MA},
    month = may,
    year = {2012},
}

@presentation{JohnsonBohland2012,
    author = {Christopher J. Johnson and
              Partha P. Mitra and
              Jason W. Bohland},
    title = {The Online Brain Atlas Reconciliation Tool (OBART): A
              web application for MRI atlas exploration and multi-atlas
              labeling},
    type = {poster},
    organization = {Society for Neuroscience 2012 Annual Meeting},
    address = {New Orleans, LA},
    year = {2012},
    month = oct
}

@presentation{Johnson2013,
    author = {Christopher J. Johnson},
    title = {Localizing Neural Representations of Speech Sounds},
    year = {2013},
    month = jun,
    type = {oral},
    organization={Second CELEST Workshop on Adaptive Brain-Computer
                  Interactions},
    address = {Boston, MA},
}

@presentation{JohnsonBohland2014a,
    author = {Christopher J. Johnson and Jason W. Bohland},
    title = {Localizing Speech Sound Representations in a Syllable
             Repetition Task},
    month = feb,
    organization = {6th Annual Inter-Science of Learning Conference},
    booktitle = {6th Annual Inter-Science of Learning Conference},
    address = {Pittsburgh, PA},
    year = {2014},
    key = {1},
    type = {poster},
}

@presentation{JohnsonBohland2014b,
    author = {Christopher J. Johnson and Jason W. \dag Bohland},
    title = {Mapping the cortical representation of speech sounds during
             syllable repetition},
    booktitle = {Society for the Neurobiology of Language Annual Meeting},
    organization = {Society for the Neurobiology of Language Annual Meeting},
    address = {Amsterdam, NL},
    month = aug,
    year = {2014},
    key = {1},
    type = {poster},
}

@presentation{Johnson2014,
    author = {Christopher J. Johnson and
              Jason W. Bohland},
    key = {1},
    type = {oral},
    title = {Localizing categorical speech representations in perception
             and production},
    booktitle = {2014 Neuroscience Meeting Planner},
    organization = {Society for Neuroscience},
    note = {Program No. 204.09},
    month = nov,
    year = {2014},
    address = {Washington, DC},
}

@presentation{Markiewicz2015,
    author = {Christopher J. Markiewicz and Jason W. Bohland},
    title = {Localizing categorical speech representations in
             perception and production},
    type = {poster},
    organization = {Neural Processing in Humans, Animals, and Man},
    address = {Boston, MA},
    month = jun,
    year = {2015}
}

@presentation{Markiewicz2016a,
    author = {Christopher J. Markiewicz and
              Kroshian, Garen S. and
              You, Jacqueline and
              \dag Bohland, Jason W.},
    title = {Multivariate analysis of input and output representations in
        speech},
    type = {poster},
    organization = {Organization for Human Brain Mapping Annual Meeting},
    address = {Geneva},
    month = jun,
    year = {2016}
}

@presentation{Markiewicz2016b,
    author = {Christopher J. Markiewicz},
    title = {Multivariate pattern analysis of input and output
        representations of speech},
    year = {2016},
    month = dec,
    type = {oral},
    organization={Boston Speech Motor Control Working Group},
    address = {Boston, MA},
}

@article{Markiewicz2016,
    author = {Christopher J. Markiewicz and Bohland, Jason W.},
    doi = {10.1016/j.neuroimage.2016.07.023},
    issn = {10538119},
    journal = {NeuroImage},
    month = nov,
    pages = {174--190},
    title = {Mapping the cortical representation of speech sounds in a syllable repetition task},
    volume = {141},
    year = {2016}
}

@presentation{Markiewicz2017,
    author = {Christopher J. Markiewicz},
    title = {Using Python for neuroimaging},
    year = {2017},
    month = mar,
    type = {oral},
    organization = {Hands-on Reproducible and Scalable Brain Imaging Analysis with Nipype},
    address = {Cambridge, MA},
}

@presentation{Markiewicz2018software,
    author = {Christopher J. Markiewicz},
    title = {FMRIprep: Building a Robust Preprocessing Pipeline for fMRI},
    year = {2018},
    month = jun,
    type = {Software demonstration},
    organization = {Organization for Human Brain Mapping Annual Meeting},
    address = {Singapore},
}

@presentation{Markiewicz2018poster,
    author = {Markiewicz, Christopher J and
              Esteban, Oscar and
              Blair, Ross W and
              Ma, Feilong and
              Kent, James D and
              Heinsfeld, Anibal S and
              Goncalves, Mathias and
              Poldrack, Russell A and
              Gorgolewski, Krzysztof J},
    title = {FMRIprep: Building a Robust Preprocessing Pipeline for fMRI},
    year = {2018},
    month = jun,
    type = {poster},
    organization = {Organization for Human Brain Mapping Annual Meeting},
    address = {Singapore},
}

@presentation{Yarkoni2018,
  title={Pybids: Python tools for manipulation and analysis of BIDS datasets},
  year={2018},
  author={Yarkoni, Tal and
          {de la Vega}, Alejandro and
          DuPre, Elizabeth and
          Esteban, Oscar and
          Halchenko, Yarik and
          Hanke, Michael and
          Hayot-Sasson, Valerie and
          Ivanov, Alexander and
          Kiar, Greg and
          Markiewicz, Chris and
          McNamara, Quinten and
          Petrov, Dmitry and
          Salo, Taylor and
          Nielson, Dylan and
          Poline, Jean-Baptiste and
          Poldrack, Russell and
          Gorgolewski, Krzysztof J},
  month=jun,
  organization={Organization for Human Brain Mapping},
  type = {poster},
  address = {Singapore},
}

@article{Esteban2018,
    author = {Esteban, Oscar and
              Markiewicz, Christopher J. and
              Blair, Ross W. and
              Moodie, Craig A. and
              Isik, A. Ilkay and
              Erramuzpe, Asier and
              Kent, James D. and
              Goncalves, Mathias and
              DuPre, Elizabeth and
              Snyder, Madeleine and
              Oya, Hiroyuki and
              Ghosh, Satrajit S. and
              Wright, Jessey and
              Durnez, Joke and
              Poldrack, Russell A. and
              Gorgolewski, Krzysztof J.},
    title = {fMRIPrep: a robust preprocessing pipeline for functional MRI},
    year = {2018},
    month = dec,
    doi = {10.1038/s41592-018-0235-4},
    isbn = {1548-7105},
    journal = {Nature Methods},
    type = {JOUR},
    note = {Preprint: \doi{10.1101/306951}}
}


@article{Esteban2020a,
    title = {Analysis of task-based functional {MRI} data preprocessed with {fMRIPrep}},
    volume = {15},
    copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
    issn = {1750-2799},
    url = {http://www.nature.com/articles/s41596-020-0327-3},
    doi = {10.1038/s41596-020-0327-3},
    abstract = {Functional magnetic resonance imaging (fMRI) is a standard tool to investigate the neural correlates of cognition. fMRI noninvasively measures brain activity, allowing identification of patterns evoked by tasks performed during scanning. Despite the long history of this technique, the idiosyncrasies of each dataset have led to the use of ad-hoc preprocessing protocols customized for nearly every different study. This approach is time consuming, error prone and unsuitable for combining datasets from many sources. Here we showcase fMRIPrep (http://fmriprep.org), a robust tool to prepare human fMRI data for statistical analysis. This software instrument addresses the reproducibility concerns of the established protocols for fMRI preprocessing. By leveraging the Brain Imaging Data Structure to standardize both the input datasets (MRI data as stored by the scanner) and the outputs (data ready for modeling and analysis), fMRIPrep is capable of preprocessing a diversity of datasets without manual intervention. In support of the growing popularity of fMRIPrep, this protocol describes how to integrate the tool in a task-based fMRI investigation workflow.},
    language = {en},
    number = {7},
    urldate = {2022-01-11},
    journal = {Nature Protocols},
    author = {Esteban, Oscar and Ciric, Rastko and Finc, Karolina and Blair, Ross W. and Markiewicz, Christopher J. and Moodie, Craig A. and Kent, James D. and Goncalves, Mathias and DuPre, Elizabeth and Gomez, Daniel E. P. and Ye, Zhifang and Salo, Taylor and Valabregue, Romain and Amlien, Inge K. and Liem, Franziskus and Jacoby, Nir and Stojić, Hrvoje and Cieslak, Matthew and Urchs, Sebastian and Halchenko, Yaroslav O. and Ghosh, Satrajit S. and De La Vega, Alejandro and Yarkoni, Tal and Wright, Jessey and Thompson, William H. and Poldrack, Russell A. and Gorgolewski, Krzysztof J.},
    month = jul,
    year = {2020},
    keywords = {Computational neuroscience, Magnetic resonance imaging, Neurological models, Software},
    pages = {2186--2202},
    note = {Preprint: \doi{10.1101/694364}},
}

@article {Esteban2019,
    author = {Esteban, Oscar and
              Ciric, Rastko and
              Finc, Karolina and
              Blair, Ross and
              Markiewicz, Christopher J. and
              Moodie, Craig A. and
              Kent, James D. and
              Goncalves, Mathias and
              DuPre, Elizabeth and
              Gomez, Daniel E. P. and
              Ye, Zhifang and
              Salo, Taylor and
              Valabregue, Romain and
              Amlien, Inge K. and
              Liem, Franziskus and
              Jacoby, Nir and
              Stoji{\'c}, Hrvoje and
              Cieslak, Matthew and
              Urchs, Sebastian and
              Halchenko, Yaroslav O. and
              Ghosh, Satrajit S. and
              {de la Vega}, Alejandro and
              Yarkoni, Tal and
              Wright, Jessey and
              Thompson, William H. and
              Poldrack, Russell A. and
              Gorgolewski, Krzysztof J.},
    title = {Analysis of task-based functional MRI data preprocessed with fMRIPrep},
    elocation-id = {694364},
    year = {2019},
    doi = {10.1101/694364},
    publisher = {Cold Spring Harbor Laboratory},
    abstract = {Functional magnetic resonance imaging (fMRI) is widely used to investigate the neural correlates of cognition. fMRI non-invasively measures brain activity, allowing identification of patterns evoked by tasks performed during scanning. Despite the long history of this technique, the idiosyncrasies of each dataset have led to the use of ad-hoc preprocessing protocols customized for nearly every different study. This approach is time-consuming, error-prone, and unsuitable for combining datasets from many sources. Here we showcase fMRIPrep, a robust preprocessing tool for virtually any human BOLD (blood-oxygen level dependent) fMRI dataset that addresses the reproducibility concerns of the established protocols for fMRI preprocessing. Based on standardizations of the input and output data specifications, fMRIPrep is capable of preprocessing a diversity of datasets without manual intervention. In support of the growing popularity of fMRIPrep, this protocol describes how to integrate the tool in a task-based fMRI investigation workflow.},
    URL = {https://www.biorxiv.org/content/early/2019/07/08/694364},
    eprint = {https://www.biorxiv.org/content/early/2019/07/08/694364.full.pdf},
    journal = {bioRxiv}
}


@article{Yarkoni2019,
  title={{PyBIDS}: Python tools for {BIDS} datasets},
  author={Yarkoni, Tal and
          Markiewicz, Christopher J and
          {de la Vega}, Alejandro and
          Gorgolewski, Krzysztof J and
          Salo, Taylor and
          Halchenko, Yarik and
          McNamara, Quinten and
          DeStasio, Krista and
          Poline, Jean-Baptiste and
          Petrov, Dmitry and
          Hayot-Sasson, Val\'erie and
          Nielson, Dylan M and
          Carlin, Johan and
          Kiar, Greg and
          Whitaker, Kirstie and
          DuPre, Elizabeth and
          Wagner, Adina and
          Tirrell, Lee and
          Jas, Mainak and
          Hanke, Michael and
          Poldrack, Russell A and
          Esteban, Oscar and
          Appelhoff, Stefan and
          Holdgraf, Chris and
          Staden, Isla and
          Thirion, Bertrand and
          Kleinschmidt, Dave F and
          Lee, John A and
          {Visconti di Oleggio Castello}, Matteo and
          Notter, Michael P and
          Blair, Ross},
  year={2019},
  month=aug,
  type = {JOUR},
  journal={Journal of Open Source Software},
  publisher = {The Open Journal},
  volume = {4},
  number = {40},
  pages = {1294},
  doi={10.21105/joss.01294},
}


@article{Poldrack2019,
 title={The importance of standards for sharing of computational models and data},
 author={Poldrack, Russell and
         Feingold, Franklin and
         Frank, Michael J and
         Gleeson, Padraig and
         de Hollander, Gilles and
         Huys, Quentin JM and
         Love, Bradley C and
         Markiewicz, Christopher J and
         Moran, Rosalyn and
         Ritter, Petra and
         Turner, Brandon M and
         Yarkoni, Tal and
         Zhan, Ming and
         Cohen, Jonathan D},
 year={2019},
 month=dec,
 type = {JOUR},
 journal={Computational Brain \& Behavior},
 volume = {2},
 number = {3-4},
 pages={229},
 doi={10.1007/s42113-019-00062-x},
 note = {Preprint: \doi{10.31234/osf.io/q3rnx}}
}

@presentation{Markiewicz2019a,
    author = {Christopher J. Markiewicz},
    title = {FitLins - Reproducible model estimation for fMRI},
    year = {2019},
    month = jun,
    type = {Software demonstration},
    organization = {Organization for Human Brain Mapping Annual Meeting},
    address = {Rome},
}


@presentation{Markiewicz2019poster,
    author = {Markiewicz, Christopher J and
              {de la Vega}, Alejandro and
              Yarkoni, Tal and
              Poldrack, Russell A and
              Gorgolewski, Krzysztof J},
    title = {FitLins - Reproducible model estimation for fMRI},
    year = {2019},
    month = jun,
    type = {poster},
    organization = {Organization for Human Brain Mapping Annual Meeting},
    address = {Rome},
}


@presentation{Markiewicz2019b,
    author = {Christopher J. Markiewicz},
    title = {fMRIPrep: A Robust fMRI Preprocessing Pipeline},
    year = {2019},
    month = oct,
    type = {oral},
    organization = {Athinoula A. Martinos Center for Biomedical Imaging},
    address = {Boston, MA},
}

@presentation{Markiewicz2019c,
    author = {Christopher J. Markiewicz},
    title = {BIDS: The Brain Imaging Data Structure},
    year = {2019},
    month = oct,
    type = {oral},
    organization = {Athinoula A. Martinos Center for Biomedical Imaging},
    address = {Boston, MA},
}

@article{Markiewicz2021,
    title = {The {OpenNeuro} resource for sharing of neuroscience data},
    volume = {10},
    copyright = {All rights reserved},
    issn = {2050-084X},
    url = {https://doi.org/10.7554/eLife.71774},
    doi = {10.7554/eLife.71774},
    abstract = {The sharing of research data is essential to ensure reproducibility and maximize the impact of public investments in scientific research. Here, we describe OpenNeuro, a BRAIN Initiative data archive that provides the ability to openly share data from a broad range of brain imaging data types following the FAIR principles for data sharing. We highlight the importance of the Brain Imaging Data Structure standard for enabling effective curation, sharing, and reuse of data. The archive presently shares more than 600 datasets including data from more than 20,000 participants, comprising multiple species and measurement modalities and a broad range of phenotypes. The impact of the shared data is evident in a growing number of published reuses, currently totalling more than 150 publications. We conclude by describing plans for future development and integration with other ongoing open science efforts.},
    urldate = {2022-01-11},
    journal = {eLife},
    author = {Markiewicz, Christopher J and Gorgolewski, Krzysztof J and Feingold, Franklin and Blair, Ross and Halchenko, Yaroslav O and Miller, Eric and Hardcastle, Nell and Wexler, Joe and Esteban, Oscar and Goncavles, Mathias and Jwa, Anita and Poldrack, Russell},
    editor = {Kahnt, Thorsten and Baker, Chris I and Dosenbach, Nico and Hawrylycz, Michael J and Svoboda, Karel},
    month = oct,
    year = {2021},
    note = {Publisher: eLife Sciences Publications, Ltd},
    keywords = {data sharing, EEG, MEG, MRI, neuroimaging, open science},
    pages = {e71774},
}

@article{DuPre2021,
  doi = {10.21105/joss.03669},
  url = {https://doi.org/10.21105/joss.03669},
  year = {2021},
  publisher = {The Open Journal},
  volume = {6},
  number = {66},
  pages = {3669},
  author = {Elizabeth DuPre and Taylor Salo and Zaki Ahmed and Peter A. Bandettini and Katherine L. Bottenhorn and César Caballero-Gaudes and Logan T. Dowdle and Javier Gonzalez-Castillo and Stephan Heunis and Prantik Kundu and Angela R. Laird and Ross Markello and Christopher J. Markiewicz and Stefano Moia and Isla Staden and Joshua B. Teves and Eneko Uruñuela and Maryam Vaziri-Pashkam and Kirstie Whitaker and Daniel A. Handwerker},
  title = {TE-dependent analysis of multi-echo fMRI with tedana},
  journal = {Journal of Open Source Software}
}

@article{Gau2021,
    title = {Brainhack: {Developing} a culture of open, inclusive, community-driven neuroscience},
    volume = {109},
    copyright = {All rights reserved},
    issn = {0896-6273},
    shorttitle = {Brainhack},
    url = {https://www.sciencedirect.com/science/article/pii/S0896627321002312},
    doi = {10.1016/j.neuron.2021.04.001},
    abstract = {Brainhack is an innovative meeting format that promotes scientific collaboration and education in an open, inclusive environment. This NeuroView describes the myriad benefits for participants and the research community and how Brainhacks complement conventional formats to augment scientific progress.},
    language = {en},
    number = {11},
    urldate = {2022-01-11},
    journal = {Neuron},
    author = {Gau, Rémi and Noble, Stephanie and Heuer, Katja and Bottenhorn, Katherine L. and Bilgin, Isil P. and Yang, Yu-Fang and Huntenburg, Julia M. and Bayer, Johanna M. M. and Bethlehem, Richard A. I. and Rhoads, Shawn A. and Vogelbacher, Christoph and Borghesani, Valentina and Levitis, Elizabeth and Wang, Hao-Ting and Van Den Bossche, Sofie and Kobeleva, Xenia and Legarreta, Jon Haitz and Guay, Samuel and Atay, Selim Melvin and Varoquaux, Gael P. and Huijser, Dorien C. and Sandström, Malin S. and Herholz, Peer and Nastase, Samuel A. and Badhwar, AmanPreet and Dumas, Guillaume and Schwab, Simon and Moia, Stefano and Dayan, Michael and Bassil, Yasmine and Brooks, Paula P. and Mancini, Matteo and Shine, James M. and O’Connor, David and Xie, Xihe and Poggiali, Davide and Friedrich, Patrick and Heinsfeld, Anibal S. and Riedl, Lydia and Toro, Roberto and Caballero-Gaudes, César and Eklund, Anders and Garner, Kelly G. and Nolan, Christopher R. and Demeter, Damion V. and Barrios, Fernando A. and Merchant, Junaid S. and McDevitt, Elizabeth A. and Oostenveld, Robert and Craddock, R. Cameron and Rokem, Ariel and Doyle, Andrew and Ghosh, Satrajit S. and Nikolaidis, Aki and Stanley, Olivia W. and Uruñuela, Eneko and Anousheh, Nasim and Arnatkeviciute, Aurina and Auzias, Guillaume and Bachar, Dipankar and Bannier, Elise and Basanisi, Ruggero and Basavaraj, Arshitha and Bedini, Marco and Bellec, Pierre and Benn, R. Austin and Berluti, Kathryn and Bollmann, Steffen and Bollmann, Saskia and Bradley, Claire and Brown, Jesse and Buchweitz, Augusto and Callahan, Patrick and Chan, Micaela Y. and Chandio, Bramsh Q. and Cheng, Theresa and Chopra, Sidhant and Chung, Ai Wern and Close, Thomas G. and Combrisson, Etienne and Cona, Giorgia and Constable, R. Todd and Cury, Claire and Dadi, Kamalaker and Damasceno, Pablo F. and Das, Samir and De Vico Fallani, Fabrizio and DeStasio, Krista and Dickie, Erin W. and Dorfschmidt, Lena and Duff, Eugene P. and DuPre, Elizabeth and Dziura, Sarah and Esper, Nathalia B. and Esteban, Oscar and Fadnavis, Shreyas and Flandin, Guillaume and Flannery, Jessica E. and Flournoy, John and Forkel, Stephanie J. and Franco, Alexandre R. and Ganesan, Saampras and Gao, Siyuan and García Alanis, José C. and Garyfallidis, Eleftherios and Glatard, Tristan and Glerean, Enrico and Gonzalez-Castillo, Javier and Gould van Praag, Cassandra D. and Greene, Abigail S. and Gupta, Geetika and Hahn, Catherine Alice and Halchenko, Yaroslav O. and Handwerker, Daniel and Hartmann, Thomas S. and Hayot-Sasson, Valérie and Heunis, Stephan and Hoffstaedter, Felix and Hohmann, Daniela M. and Horien, Corey and Ioanas, Horea-Ioan and Iordan, Alexandru and Jiang, Chao and Joseph, Michael and Kai, Jason and Karakuzu, Agah and Kennedy, David N. and Keshavan, Anisha and Khan, Ali R. and Kiar, Gregory and Klink, P. Christiaan and Koppelmans, Vincent and Koudoro, Serge and Laird, Angela R. and Langs, Georg and Laws, Marissa and Licandro, Roxane and Liew, Sook-Lei and Lipic, Tomislav and Litinas, Krisanne and Lurie, Daniel J. and Lussier, Désirée and Madan, Christopher R. and Mais, Lea-Theresa and Mansour L, Sina and Manzano-Patron, J. P. and Maoutsa, Dimitra and Marcon, Matheus and Margulies, Daniel S. and Marinato, Giorgio and Marinazzo, Daniele and Markiewicz, Christopher J. and Maumet, Camille and Meneguzzi, Felipe and Meunier, David and Milham, Michael P. and Mills, Kathryn L. and Momi, Davide and Moreau, Clara A. and Motala, Aysha and Moxon-Emre, Iska and Nichols, Thomas E. and Nielson, Dylan M. and Nilsonne, Gustav and Novello, Lisa and O’Brien, Caroline and Olafson, Emily and Oliver, Lindsay D. and Onofrey, John A. and Orchard, Edwina R. and Oudyk, Kendra and Park, Patrick J. and Parsapoor, Mahboobeh and Pasquini, Lorenzo and Peltier, Scott and Pernet, Cyril R. and Pienaar, Rudolph and Pinheiro-Chagas, Pedro and Poline, Jean-Baptiste and Qiu, Anqi and Quendera, Tiago and Rice, Laura C. and Rocha-Hidalgo, Joscelin and Rutherford, Saige and Scharinger, Mathias and Scheinost, Dustin and Shariq, Deena and Shaw, Thomas B. and Siless, Viviana and Simmonite, Molly and Sirmpilatze, Nikoloz and Spence, Hayli and Sprenger, Julia and Stajduhar, Andrija and Szinte, Martin and Takerkart, Sylvain and Tam, Angela and Tejavibulya, Link and Thiebaut de Schotten, Michel and Thome, Ina and Tomaz da Silva, Laura and Traut, Nicolas and Uddin, Lucina Q. and Vallesi, Antonino and VanMeter, John W. and Vijayakumar, Nandita and di Oleggio Castello, Matteo Visconti and Vohryzek, Jakub and Vukojević, Jakša and Whitaker, Kirstie Jane and Whitmore, Lucy and Wideman, Steve and Witt, Suzanne T. and Xie, Hua and Xu, Ting and Yan, Chao-Gan and Yeh, Fang-Cheng and Yeo, B. T. Thomas and Zuo, Xi-Nian},
    month = jun,
    year = {2021},
    keywords = {open science, best practices, Brainhack, collaboration, community building, hackathon, inclusivity, neuroscience, reproducibility, training},
    pages = {1769--1775},
}


@article{Halchenko2021,
    title = {{DataLad}: distributed system for joint management of code, data, and their relationship},
    volume = {6},
    issn = {2475-9066},
    shorttitle = {{DataLad}},
    url = {https://joss.theoj.org/papers/10.21105/joss.03262},
    doi = {10.21105/joss.03262},
    abstract = {Halchenko et al., (2021). DataLad: distributed system for joint management of code, data, and their relationship. Journal of Open Source Software, 6(63), 3262, https://doi.org/10.21105/joss.03262},
    language = {en},
    number = {63},
    urldate = {2022-01-11},
    journal = {Journal of Open Source Software},
    author = {Halchenko, Yaroslav O. and Meyer, Kyle and Poldrack, Benjamin and Solanky, Debanjum Singh and Wagner, Adina S. and Gors, Jason and MacFarlane, Dave and Pustina, Dorian and Sochat, Vanessa and Ghosh, Satrajit S. and Mönch, Christian and Markiewicz, Christopher J. and Waite, Laura and Shlyakhter, Ilya and de la Vega, Alejandro and Hayashi, Soichi and Häusler, Christian Olaf and Poline, Jean-Baptiste and Kadelka, Tobias and Skytén, Kusti and Jarecka, Dorota and Kennedy, David and Strauss, Ted and Cieslak, Matt and Vavra, Peter and Ioanas, Horea-Ioan and Schneider, Robin and Pflüger, Mika and Haxby, James V. and Eickhoff, Simon B. and Hanke, Michael},
    month = jul,
    year = {2021},
    pages = {3262},
}


@article{Hanke2021,
    title = {In defense of decentralized research data management},
    volume = {27},
    copyright = {All rights reserved},
    issn = {1868-856X},
    url = {http://www.degruyter.com/document/doi/10.1515/nf-2020-0037/html},
    doi = {10.1515/nf-2020-0037},
    abstract = {Decentralized research data management (dRDM) systems handle digital research objects across participating nodes without critically relying on central services. We present four perspectives in defense of dRDM, illustrating that, in contrast to centralized or federated research data management solutions, a dRDM system based on heterogeneous but interoperable components can offer a sustainable, resilient, inclusive, and adaptive infrastructure for scientific stakeholders: An individual scientist or laboratory, a research institute, a domain data archive or cloud computing platform, and a collaborative multisite consortium. All perspectives share the use of a common, self-contained, portable data structure as an abstraction from current technology and service choices. In conjunction, the four perspectives review how varying requirements of independent scientific stakeholders can be addressed by a scalable, uniform dRDM solution and present a working system as an exemplary implementation.},
    language = {en},
    number = {1},
    urldate = {2022-01-11},
    journal = {Neuroforum},
    author = {Hanke, Michael and Pestilli, Franco and Wagner, Adina S. and Markiewicz, Christopher J. and Poline, Jean-Baptiste and Halchenko, Yaroslav O.},
    month = feb,
    year = {2021},
    note = {Publisher: De Gruyter},
    keywords = {BrainLife, Canadian Open Neuroscience Platform, DataLad, Interoperability, OpenNeuro},
    pages = {17--25},
}


@article{Goncalves2021,
    title = {{NiTransforms}: {A} {Python} tool to read, represent, manipulate, and apply $n$-dimensional spatial transforms},
    volume = {6},
    copyright = {All rights reserved},
    issn = {2475-9066},
    shorttitle = {{NiTransforms}},
    url = {https://joss.theoj.org/papers/10.21105/joss.03459},
    doi = {10.21105/joss.03459},
    abstract = {Goncalves et al., (2021). NiTransforms: A Python tool to read, represent, manipulate, and apply \$n\$-dimensional spatial transforms. Journal of Open Source Software, 6(65), 3459, https://doi.org/10.21105/joss.03459},
    language = {en},
    number = {65},
    urldate = {2022-01-11},
    journal = {Journal of Open Source Software},
    author = {Goncalves, Mathias and Markiewicz, Christopher J. and Moia, Stefano and Ghosh, Satrajit S. and Poldrack, Russell A. and Esteban, Oscar},
    month = sep,
    year = {2021},
    pages = {3459},
}



@techreport{Ciric2021,
    title = {{TemplateFlow}: {FAIR}-sharing of multi-scale, multi-species brain models},
    copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
    shorttitle = {{TemplateFlow}},
    url = {https://www.biorxiv.org/content/10.1101/2021.02.10.430678v3},
    abstract = {Reference anatomies of the brain and corresponding atlases play a central role in experimental neuroimaging workflows and are the foundation for reporting standardized results. The choice of such references —i.e., templates— and atlases is one relevant source of methodological variability across studies, which has recently been brought to attention as an important challenge to reproducibility in neuroscience. TemplateFlow is a publicly available framework for human and nonhuman brain models. The framework combines an open database with software for access, management, and vetting, allowing scientists to distribute their resources under FAIR —findable, accessible, interoperable, reusable— principles. TemplateFlow supports a multifaceted insight into brains across species, and enables multiverse analyses testing whether results generalize across standard references, scales, and in the long term, species, thereby contributing to increasing the reliability of neuroimaging results.},
    language = {en},
    urldate = {2022-01-11},
    author = {Ciric, Rastko and Thompson, William H. and Lorenz, Romy and Goncalves, Mathias and MacNicol, Eilidh and Markiewicz, Christopher J. and Halchenko, Yaroslav O. and Ghosh, Satrajit S. and Gorgolewski, Krzysztof J. and Poldrack, Russell A. and Esteban, Oscar},
    month = aug,
    year = {2021},
    doi = {10.1101/2021.02.10.430678},
    note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
    pages = {2021.02.10.430678},
}

@techreport{Bansal2021,
    title = {High-sensitivity detection of facial features on {MRI} brain scans with a convolutional network},
    copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
    url = {https://www.biorxiv.org/content/10.1101/2021.04.25.441373v1},
    abstract = {Platforms and institutions that support MRI data sharing need to ensure that identifiable facial features are not present in shared images. Currently, this assessment requires manual effect as no auto-mated tools exist that can efficiently and accurately detect if an image has been “defaced”. The scarcity of publicly available data with pre-served facial features, as well as the meager incentives to create such a cohort privately, have averted the development of face-detection models. Here, we introduce a framework to detect whether an input MRI brain scan has been defaced, with the ultimate goal of streamlining it within the submission protocols of MRI data archiving and sharing platforms. We present a binary (defaced/”nondefaced”) classifier based on a custom convolutional neural network architecture. We train the model on 980 de-faced MRI scans from 36 different studies that are publicly available at OpenNeuro.org. To overcome the unavailability of nondefaced examples, we augment the dataset by inpainting synthetic faces into each training image. We show the adequacy of such a data augmentation in a cross-validation evaluation. We demonstrate the performance estimated with cross-validation matches that of an evaluation on a held-out dataset (N =581) preserving real faces, and obtain accuracy/sensitivity/speci-ficity scores of 0.978/0.983/0.972, respectively. Data augmentations are key to boosting the performance of models bounded by limited sample sizes and insufficient diversity. Our model contributes towards developing classifiers with ∼100\% sensitivity detecting faces, which is crucial to ensure that no identifiable data are inadvertently made public.},
    language = {en},
    urldate = {2022-01-11},
    author = {Bansal, Shashank and Kori, Avinash and Zulfikar, Wazeer and Wexler, Joseph and Markiewicz, Christopher J. and Feingold, Franklin F. and Poldrack, Russell A. and Esteban, Oscar},
    month = apr,
    year = {2021},
    doi = {10.1101/2021.04.25.441373},
    note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
    pages = {2021.04.25.441373},
}


@techreport{Norgaard2021,
    title = {{PET}-{BIDS}, an extension to the brain imaging data structure for positron emission tomography},
    copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
    url = {https://www.biorxiv.org/content/10.1101/2021.06.16.448390v1},
    abstract = {The Brain Imaging Data Structure (BIDS) is a standard for organizing and describing neuroimaging datasets. It serves not only to facilitate the process of data sharing and aggregation, but also to simplify the application and development of new methods and software for working with neuroimaging data. Here, we present an extension of BIDS to include positron emission tomography (PET) data (PET-BIDS). We describe the PET-BIDS standard in detail and share several open-access datasets curated following PET-BIDS. Additionally, we highlight several tools which are already available for converting, validating and analyzing PET-BIDS datasets.},
    language = {en},
    urldate = {2022-01-11},
    author = {Norgaard, Martin and Matheson, Granville J. and Hansen, Hanne D. and Thomas, Adam and Searle, Graham and Rizzo, Gaia and Veronese, Mattia and Giacomel, Alessio and Yaqub, Maqsood and Tonietto, Matteo and Funck, Thomas and Gillman, Ashley and Boniface, Hugo and Routier, Alexandre and Dalenberg, Jelle R. and Betthauser, Tobey and Feingold, Franklin and Markiewicz, Christopher J. and Gorgolewski, Krzysztof J. and Blair, Ross W. and Appelhoff, Stefan and Gau, Remi and Salo, Taylor and Niso, Guiomar and Pernet, Cyril and Phillips, Christophe and Oostenveld, Robert and Gallezot, Jean-Dominique and Carson, Richard E. and Knudsen, Gitte M. and Innis, Robert B. and Ganz, Melanie},
    month = jun,
    year = {2021},
    doi = {10.1101/2021.06.16.448390},
    note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
    pages = {2021.06.16.448390},
}

@techreport{Karakuzu2021,
    title = {{qMRI}-{BIDS}: an extension to the brain imaging data structure for quantitative magnetic resonance imaging data},
    copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
    shorttitle = {{qMRI}-{BIDS}},
    url = {https://www.medrxiv.org/content/10.1101/2021.10.22.21265382v3},
    abstract = {The Brain Imaging Data Structure (BIDS) established community consensus on the organization of data and metadata for several neuroimaging modalities. Traditionally, BIDS had a strong focus on functional magnetic resonance imaging (MRI) datasets and lacked guidance on how to store multimodal structural MRI datasets. Here, we present and describe the BIDS Extension Proposal 001 (BEP001), which adds a range of quantitative MRI (qMRI) applications to the BIDS application sphere. In general, the aim of qMRI is to characterize brain microstructure by quantifying the physical MR parameters of the tissue via computational, biophysical models. By proposing this new standard, we envision standardization of qMRI which makes multicenter dissemination of interoperable data possible. As a result, BIDS can act as a catalyst of convergence between qMRI methods development and application-driven neuroimaging studies that can help develop quantitative biomarkers for neural tissue characterization. Finally, our BIDS extension offers a common ground for developers to exchange novel imaging data and tools, reducing the practical barriers to standardization that is currently lacking in the field of neuroimaging.},
    language = {en},
    urldate = {2022-01-11},
    author = {Karakuzu, Agah and Appelhoff, Stefan and Auer, Tibor and Boudreau, Mathieu and Feingold, Franklin and Khan, Ali R. and Lazari, Alberto and Markiewicz, Christopher J. and Mulder, Martijn J. and Phillips, Christophe and Salo, Taylor and Stikov, Nikola and Whitaker, Kirstie and Hollander, Gilles de},
    month = oct,
    year = {2021},
    doi = {10.1101/2021.10.22.21265382},
    note = {Company: Cold Spring Harbor Laboratory Press
Distributor: Cold Spring Harbor Laboratory Press
Label: Cold Spring Harbor Laboratory Press
Type: article},
    pages = {2021.10.22.21265382},
}

@inproceedings{Esteban2020b,
    title = {Software {Tool} to {Read}, {Represent}, {Manipulate}, and {Apply} {N}-{Dimensional} {Spatial} {Transforms}},
    copyright = {All rights reserved},
    doi = {10.1109/ISBI45749.2020.9098466},
    abstract = {Spatial transforms formalize mappings between coordinates of objects in biomedical images. Transforms typically are the outcome of image registration methodologies, which estimate the alignment between two images. Image registration is a prominent task present in nearly all standard image processing and analysis pipelines. The proliferation of software implementations of image registration methodologies has resulted in a spread of data structures and file formats used to preserve and communicate transforms. This segregation of formats hinders the compatibility between tools and endangers the reproducibility of results. We propose a software tool capable of converting between formats and resampling images to apply transforms generated by the most popular neuroimaging packages and libraries (AFNI, FSL, FreeSurfer, ITK, and SPM). The proposed software is subject to continuous integration tests to check the compatibility with each supported tool after every change to the code base (https://github.com/poldracklab/nitransforms). Compatibility between software tools and imaging formats is a necessary bridge to ensure the reproducibility of results and enable the optimization and evaluation of current image processing and analysis workflows.},
    booktitle = {2020 {IEEE} 17th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI})},
    author = {Esteban, O. and Goncalves, M. and Markiewicz, C. J. and Ghosh, S. S. and Poldrack, R. A.},
    month = apr,
    year = {2020},
    note = {ISSN: 1945-8452},
    keywords = {BIDS, image registration, Image registration, Pipelines, software infrastructure, Software tools, spatial transforms, Standards, Tools, Transforms},
    pages = {709--712},
}

@article{Moreau2020,
    title = {The genetics-{BIDS} extension: {Easing} the search for genetic data associated with human brain imaging},
    volume = {9},
    copyright = {All rights reserved},
    issn = {2047-217X},
    shorttitle = {The genetics-{BIDS} extension},
    url = {https://doi.org/10.1093/gigascience/giaa104},
    doi = {10.1093/gigascience/giaa104},
    abstract = {Metadata are what makes databases searchable. Without them, researchers would have difficulty finding data with features they are interested in. Brain imaging genetics is at the intersection of two disciplines, each with dedicated dictionaries and ontologies facilitating data search and analysis. Here, we present the genetics Brain Imaging Data Structure extension, consisting of metadata files for human brain imaging data to which they are linked, and describe succinctly the genomic and transcriptomic data associated with them, which may be in different databases. This extension will facilitate identifying micro-scale molecular features that are linked to macro-scale imaging repositories, facilitating data aggregation across studies.},
    number = {10},
    urldate = {2022-01-11},
    journal = {GigaScience},
    author = {Moreau, Clara A and Jean-Louis, Martineau and Blair, Ross and Markiewicz, Christopher J and Turner, Jessica A and Calhoun, Vince D and Nichols, Thomas E and Pernet, Cyril R},
    month = oct,
    year = {2020},
    pages = {giaa104},
}


@misc{philips-cdas,
    author = {Christopher J. Markiewicz},
    title = {philips-cdas v0.1},
    month = apr,
    year = 2016,
    doi = {10.5281/zenodo.49853},
}

@misc{You2015,
    author = {You, Jacqueline and Markiewicz, Christopher J. and
              Bohland, Jason W.},
    title = {Formant detection scripts for ``{Mapping the cortical representation of speech sounds in a syllable repetition task}''},
    month = jul,
    year = {2015},
    doi = {10.5281/zenodo.51362}
}

@software{FitLins0_6_2,
  author       = {Markiewicz, Christopher J. and
                  de la Vega, Alejandro and
                  Wagner, Adina and
                  Halchenko, Yaroslav O. and
                  Finc, Karolina and
                  Ciric, Rastko and
                  Goncalves, Mathias and
                  Nielson, Dylan M. and
                  Poldrack, Russell A. and
                  Gorgolewski, Krzysztof J.},
  title        = {poldracklab/fitlins: 0.6.2},
  month        = dec,
  year         = 2019,
  publisher    = {Zenodo},
  version      = {0.6.2},
  doi          = {10.5281/zenodo.3575117},
  url          = {https://doi.org/10.5281/zenodo.3575117}
}

@software{fMRIPrep1_5_4,
  author       = {Esteban, Oscar and
                  Markiewicz, Christopher J. and
                  DuPre, Elizabeth and
                  Kent, James D. and
                  Ciric, Rastko and
                  Goncalves, Mathias and
                  Blair, Ross W. and
                  Poldrack, Russell A. and
                  Gorgolewski, Krzysztof J.},
  title        = {{fMRIPrep: a robust preprocessing pipeline for
                   functional MRI}},
  month        = dec,
  year         = 2019,
  publisher    = {Zenodo},
  version      = {1.5.4},
  doi          = {10.5281/zenodo.3583200},
  url          = {https://doi.org/10.5281/zenodo.3583200}
}

@misc{PyMVPA2_4_1,
  author       = {Yaroslav Halchenko and
                  Michael Hanke and
                  Nikolaas N. Oosterhof and
                  Emanuele Olivetti and
                  Per B. Sederberg and
                  Swaroop Guntupalli and
                  Tiziano Zito and
                  Valentin Haenel and
                  Sven Buchholz and
                  Richard Dinga and
                  Arman Eshaghi and
                  David Armstrong and
                  Adam Riggall and
                  Christoph Gohlke and
                  Chris Markiewicz and
                  Michael Notter and
                  Matthias Ekman and
                  Cameron Chen and
                  Kelsey Wheeler and
                  Satrajit Ghosh and
                  Reka Daniel-Weiner and
                  Matteo Visconti di Oleggio Castello and
                  Geethapriya Raghavan and
                  Andrew Connolly and
                  Feilong Ma},
  title        = {PyMVPA: 2.4.1},
  month        = nov,
  year         = 2015,
  doi          = {10.5281/zenodo.33988},
  url          = {http://dx.doi.org/10.5281/zenodo.33988}
}

@software{nipype1_4_0,
  author       = {Esteban, Oscar and
                  Markiewicz, Christopher J. and
                  Burns, Christopher and
                  Johnson, Hans and
                  Ziegler, Erik and
                  Manhães-Savio, Alexandre and
                  Jarecka, Dorota and
                  Ellis, David Gage and
                  Yvernault, Benjamin and
                  Hamalainen, Carlo and
                  Notter, Michael Philipp and
                  Salo, Taylor and
                  Waskom, Michael and
                  Goncalves, Mathias and
                  Jordan, Kesshi and
                  Wong, Jason and
                  Dewey, Blake E and
                  Madison, Cindee and
                  Clark, Daniel and
                  Loney, Fred and
                  Clark, Dav and
                  Nielson, Dylan M. and
                  Keshavan, Anisha and
                  Joseph, Michael and
                  Dayan, Michael and
                  Modat, Marc and
                  Bougacha, Salma and
                  Gramfort, Alexandre and
                  Visconti di Oleggio Castello, Matteo and
                  Pinsard, Basile and
                  Berleant, Shoshana and
                  Christian, Horea and
                  Rokem, Ariel and
                  Halchenko, Yaroslav O. and
                  Kaczmarzyk, Jakub and
                  Benderoff, Erin and
                  Ćirić , Rastko and
                  Varoquaux, Gael and
                  Moloney, Brendan and
                  DuPre, Elizabeth and
                  Koudoro, Serge and
                  Clark, Michael G. and
                  Wassermann, Demian and
                  Cipollini, Ben and
                  Guillon, Jérémy and
                  Markello, Ross and
                  Buchanan, Colin and
                  Hanke, Michael and
                  Tungaraza, Rosalia and
                  Sikka, Sharad and
                  Gillman, Ashley and
                  Pauli, Wolfgang M. and
                  de Hollander, Gilles and
                  Forbes, Jessica and
                  Iqbal, Shariq and
                  Mordom, David and
                  Mancini, Matteo and
                  Malone, Ian B. and
                  Dubois, Mathieu and
                  Schwartz, Yannick and
                  Frohlich, Caroline and
                  Tabas, Alejandro and
                  Welch, David and
                  Richie-Halford, Adam and
                  Tilley II, Steven and
                  Watanabe, Aimi and
                  Nichols, B. Nolan and
                  Huntenburg, Julia M. and
                  Eshaghi, Arman and
                  Schaefer, Alexander and
                  Ginsburg, Daniel and
                  Bottenhorn, Katherine and
                  Cumba, Chad and
                  Acland, Benjamin and
                  Heinsfeld, Anibal Sólon and
                  Kastman, Erik and
                  Kent, James and
                  Kleesiek, Jens and
                  Erickson, Drew and
                  Giavasis, Steven and
                  Ghayoor, Ali and
                  Liem, Franz and
                  De La Vega, Alejandro and
                  Küttner, René and
                  Millman, Jarrod and
                  Perez-Guevara, Martin Felipe and
                  Lee, John A. and
                  Zhou, Dale and
                  Haselgrove, Christian and
                  Glen, Daniel and
                  Renfro, Mandy and
                  Correa, Carlos and
                  Liu, Siqi and
                  Lampe, Leonie and
                  Kong, Xiang-Zhen and
                  Hallquist, Michael and
                  Kahn, Ari E. and
                  Glatard, Tristan and
                  Triplett, William and
                  Chawla, Kshitij and
                  Salvatore, John and
                  Pérez-García, Fernando and
                  Ma, Feilong and
                  Park, Anne and
                  Craddock, R. Cameron and
                  Hinds, Oliver and
                  Poldrack, Russell and
                  Perkins, L. Nathan and
                  Kim, Sin and
                  Chetverikov, Andrey and
                  Inati, Souheil and
                  Cieslak, Matthew and
                  Grignard, Martin and
                  Snoek, Lukas and
                  Sisk, Lucinda M. and
                  Leinweber, Katrin and
                  Junhao WEN and
                  Matsubara, K and
                  Urchs, Sebastian and
                  Blair, Ross and
                  Floren, Andrew and
                  Mattfeld, Aaron and
                  Gerhard, Stephan and
                  Cooper, Gavin and
                  Haehn, Daniel and
                  Tambini, Arielle and
                  Broderick, William and
                  Andberg, Sami Kristian and
                  Noel, Maxime and
                  Durnez, Joke and
                  Stadler, Jörg and
                  Condamine, Eric and
                  Papadopoulos Orfanos, Dimitri and
                  Geisler, Daniel and
                  Weinstein, Alejandro and
                  Harms, Robbert and
                  Khanuja, Ranjeet and
                  Sharp, Paul and
                  Stanley, Olivia and
                  Lee, Nat and
                  Crusoe, Michael R. and
                  Brett, Matthew and
                  Falkiewicz, Marcel and
                  Podranski, Kornelius and
                  Linkersdörfer, Janosch and
                  Flandin, Guillaume and
                  Lerma-Usabiaga, Garikoitz and
                  Shachnev, Dmitry and
                  Tarbert, Claire and
                  Cheung, Brian and
                  Meyers, Benjamin and
                  Van, Andrew and
                  Davison, Andrew and
                  Weninger, Leon and
                  Molina-Romero, Miguel and
                  Rothmei, Simon and
                  Bilgel, Murat and
                  Schlamp, Kai and
                  Ort, Eduard and
                  McNamee, Daniel and
                  Lai, Jeff and
                  Arias, Jaime and
                  Bielievtsov, Dmytro and
                  Steele, Christopher John and
                  Huang, Lijie and
                  Gonzalez, Ivan and
                  Warner, Joshua and
                  Margulies, Daniel S. and
                  Contier, Oliver and
                  Marina, Ana and
                  Saase, Victor and
                  Nickson, Thomas and
                  Varada, Jan and
                  Schwabacher, Isaac and
                  Pellman, John and
                  Khanuja, Ranjeet and
                  Pannetier, Nicolas and
                  McDermottroe, Conor and
                  Mihai, Paul Glad and
                  Lai, Jeff and
                  Gorgolewski, Krzysztof J. and
                  Ghosh, Satrajit},
  title        = {nipy/nipype: 1.4.0},
  month        = dec,
  year         = 2019,
  publisher    = {Zenodo},
  version      = {1.4.0},
  doi          = {10.5281/zenodo.3588470},
  url          = {https://doi.org/10.5281/zenodo.3588470}
}

@misc{PySurfer0_9,
  author       = {Michael Waskom and
                  Eric Larson and
                  Christian Brodbeck and
                  Alexandre Gramfort and
                  Scott Burns and
                  Martin Luessi and
                  Christoph T. Weidemann and
                  Sebastian Bitzer and
                  Chris Markiewicz and
                  Roan LaPlante and
                  Denis A. Engemann and
                  Yaroslav Halchenko and
                  Satrajit Ghosh and
                  Natalie Klein and
                  Diego Angulo and
                  Marijn van Vliet and
                  Gio Piantoni and
                  Matthew Brett and
                  Laura Gwilliams},
  title        = {PySurfer: 0.9.0},
  month        = oct,
  year         = 2018,
  doi          = {10.5281/zenodo.1443483},
  url          = {https://doi.org/10.5281/zenodo.1443483}
}

@software{nibabel3_0_0,
  author       = {Brett, Matthew and
                  Markiewicz, Christopher J. and
                  Hanke, Michael and
                  Côté, Marc-Alexandre and
                  Cipollini, Ben and
                  McCarthy, Paul and
                  Cheng, Christopher P. and
                  Halchenko, Yaroslav O. and
                  Cottaar, Michiel and
                  Ghosh, Satrajit and
                  Larson, Eric and
                  Wassermann, Demian and
                  Gerhard, Stephan and
                  Lee, Gregory R. and
                  Wang, Hao-Ting and
                  Kastman, Erik and
                  Rokem, Ariel and
                  Madison, Cindee and
                  Morency, Félix C. and
                  Moloney, Brendan and
                  Goncalves, Mathias and
                  Riddell, Cameron and
                  Burns, Christopher and
                  Millman, Jarrod and
                  Gramfort, Alexandre and
                  Leppäkangas, Jaakko and
                  Markello, Ross and
                  van den Bosch, Jasper J.F. and
                  Vincent, Robert D. and
                  Braun, Henry and
                  Subramaniam, Krish and
                  Jarecka, Dorota and
                  Gorgolewski, Krzysztof J. and
                  Raamana, Pradeep Reddy and
                  Nichols, B. Nolan and
                  Baker, Eric M. and
                  Hayashi, Soichi and
                  Pinsard, Basile and
                  Haselgrove, Christian and
                  Hymers, Mark and
                  Esteban, Oscar and
                  Koudoro, Serge and
                  Oosterhof, Nikolaas N. and
                  Amirbekian, Bago and
                  Nimmo-Smith, Ian and
                  Nguyen, Ly and
                  Reddigari, Samir and
                  St-Jean, Samuel and
                  Panfilov, Egor and
                  Garyfallidis, Eleftherios and
                  Varoquaux, Gael and
                  Kaczmarzyk, Jakub and
                  Legarreta, Jon Haitz and
                  Hahn, Kevin S. and
                  Hinds, Oliver P. and
                  Fauber, Bennet and
                  Poline, Jean-Baptiste and
                  Stutters, Jon and
                  Jordan, Kesshi and
                  Cieslak, Matthew and
                  Moreno, Miguel Estevan and
                  Haenel, Valentin and
                  Schwartz, Yannick and
                  Thirion, Bertrand and
                  Papadopoulos Orfanos, Dimitri and
                  Pérez-García, Fernando and
                  Solovey, Igor and
                  Gonzalez, Ivan and
                  Palasubramaniam, Jath and
                  Lecher, Justin and
                  Leinweber, Katrin and
                  Raktivan, Konstantinos and
                  Fischer, Peter and
                  Gervais, Philippe and
                  Gadde, Syam and
                  Ballinger, Thomas and
                  Roos, Thomas and
                  Reddam, Venkateswara Reddy and
                  freec84},
  title        = {nipy/nibabel: 3.0.0},
  month        = dec,
  year         = 2019,
  publisher    = {Zenodo},
  version      = {3.0.0},
  doi          = {10.5281/zenodo.3583002},
  url          = {https://doi.org/10.5281/zenodo.3583002}
}
